{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPN - Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import pyreadstat as ps\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read\n",
    "aut_data, aut_meta = ps.read_sav('MPNWAVE8_AUTOdata.sav')\n",
    "dab_data, dab_meta = ps.read_sav('MPNWAVE8_DAGBOEKdata.sav')\n",
    "dag_data, dag_meta = ps.read_sav('MPNWAVE8_DAGdata.sav')\n",
    "hhd_data, hhd_meta = ps.read_sav('MPNWAVE8_HHdata.sav')\n",
    "pda_data, pda_meta = ps.read_sav('MPNWAVE8_Pdata.sav')\n",
    "pbz_data, pbz_meta = ps.read_sav('MPNWAVE8_Pdata_bijzonder.sav')\n",
    "wee_data, wee_meta = ps.read_sav('MPNWAVE8_weegfactoren.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean aut\n",
    "aut_dropcols = ['KENTEKENS_INGEVULD', 'AUTO1_BRANDSTOF_A_w6', 'AUTO1_BRANDSTOF_B_w6', 'AUTO1_BIJTELLING_w5', 'AUTO1_GEWMAX', 'AUTO1_GEWLEEG',  'AUTO1_HLID5', 'AUTO1_HLID6', 'AUTO1_HLID7', 'AUTO1_HLID8', 'AUTO1_HLID9', 'AUTO1_HLID10', 'AUTO1_HLID11', 'AUTO1_HLID12', 'AUTO1_HLID13', 'AUTO2_BRANDSTOF_A_w6', 'AUTO2_BRANDSTOF_B_w6', 'AUTO2_BIJTELLING_w5','AUTO2_GEWMAX', 'AUTO2_GEWLEEG', 'AUTO2_HLID5', 'AUTO2_HLID6', 'AUTO2_HLID7', 'AUTO2_HLID8', 'AUTO2_HLID9', 'AUTO2_HLID10', 'AUTO2_HLID11', 'AUTO2_HLID12', 'AUTO2_HLID13', 'AUTO3_BRANDSTOF_A_w6', 'AUTO3_BRANDSTOF_B_w6', 'AUTO3_BIJTELLING_w5', 'AUTO3_GEWMAX', 'AUTO3_GEWLEEG', 'AUTO3_HLID5', 'AUTO3_HLID6', 'AUTO3_HLID7', 'AUTO3_HLID8', 'AUTO3_HLID9', 'AUTO3_HLID10', 'AUTO3_HLID11', 'AUTO3_HLID12','AUTO3_HLID13','AUTO4_GEWLEEG', 'AUTO4_BRANDSTOF_A_w6', 'AUTO4_BRANDSTOF_B_w6', 'AUTO4_BIJTELLING_w5','AUTO4_HLID5', 'AUTO4_HLID6', 'AUTO4_HLID7', 'AUTO4_HLID8', 'AUTO4_HLID9', 'AUTO4_HLID10', 'AUTO4_HLID11', 'AUTO4_HLID12', 'AUTO4_HLID13', 'AUTO5_BRANDSTOF_A_w6', 'AUTO5_BRANDSTOF_B_w6', 'AUTO5_BIJTELLING_w5', 'AUTO5_GEWMAX', 'AUTO5_GEWLEEG', 'AUTO5_HLID5', 'AUTO5_HLID6', 'AUTO5_HLID7', 'AUTO5_HLID8', 'AUTO5_HLID9', 'AUTO5_HLID10', 'AUTO5_HLID11', 'AUTO5_HLID12', 'AUTO5_HLID13',]\n",
    "aut_80nan = aut_data.columns[aut_data.isna().mean() > 0.8].tolist()\n",
    "aut_drop = aut_dropcols + aut_80nan\n",
    "aut = aut_data.drop(columns=aut_drop, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean dab\n",
    "dab_dropcols = []\n",
    "dab_80nan = dab_data.columns[dab_data.isna().mean() > 0.8].tolist()\n",
    "dab_drop = dab_dropcols + dab_80nan\n",
    "dab = dab_data.drop(columns=dab_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean dag\n",
    "dag_dropcols = []\n",
    "dag_80nan = dag_data.columns[dag_data.isna().mean() > 0.8].tolist()\n",
    "dag_drop = dag_dropcols + dag_80nan\n",
    "dag = dag_data.drop(columns=dag_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'hhd' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "# Clean hhd\n",
    "hhd_dropcols = ['PROV', 'HHMOTOR', 'HHBROM', 'HHSNOR', 'HHFIETS', 'HHVOUWFIETS', 'HHEBIKE', 'HHPEDEL', 'HHSCOOT', 'HHOVG', 'HHGEEN', 'KENTEKENINFO', 'woonpc2']\n",
    "hhd_80nan = hhd_data.columns[hhd_data.isna().mean() > 0.8].tolist()\n",
    "hhd_drop = hhd_dropcols + hhd_80nan\n",
    "hhd = hhd_data.drop(columns=hhd_drop, axis=1)\n",
    "\n",
    "%store hhd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean pda\n",
    "\n",
    "pda_dropcols = ['HH_VALID']\n",
    "pda_80nan = pda_data.columns[pda_data.isna().mean() > 0.8].tolist()\n",
    "pda_drop = pda_dropcols + pda_80nan\n",
    "pda = pda_data.drop(columns=pda_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean pbz\n",
    "\n",
    "pbz_dropcols = ['OORDEEL_TREIN', 'OORDEEL_BTM', 'OORDEEL_FIETS', 'OORDEEL_BROMMER', 'OORDEEL_LOPEN', 'OORDEEL_VLIEGTUIG', 'GEBRUIK_TREIN_STELLING1', 'GEBRUIK_TREIN_STELLING2', 'GEBRUIK_TREIN_STELLING3', 'GEBRUIK_TREIN_STELLING4', 'GEBRUIK_TREIN_STELLING5', 'GEBRUIK_TREIN_STELLING6', 'GEBRUIK_TREIN_STELLING7', 'GEBRUIK_BTM_STELLING1', 'GEBRUIK_BTM_STELLING2', 'GEBRUIK_BTM_STELLING3', 'GEBRUIK_BTM_STELLING4', 'GEBRUIK_BTM_STELLING5', 'GEBRUIK_BTM_STELLING6', 'GEBRUIK_BTM_STELLING7', 'GEBRUIK_FIETS_STELLING1', 'GEBRUIK_FIETS_STELLING2', 'GEBRUIK_FIETS_STELLING3', 'GEBRUIK_FIETS_STELLING4', 'GEBRUIK_FIETS_STELLING5', 'GEBRUIK_FIETS_STELLING6', 'GEBRUIK_FIETS_STELLING7', 'GEBRUIK_LOPEN_STELLING1', 'GEBRUIK_LOPEN_STELLING2', 'GEBRUIK_LOPEN_STELLING3', 'GEBRUIK_LOPEN_STELLING4', 'GEBRUIK_LOPEN_STELLING5', 'GEBRUIK_LOPEN_STELLING6', 'GEBRUIK_LOPEN_STELLING7', 'VVM_TOEKOMST_ANDERS_TREIN', 'VVM_TOEKOMST_ANDERS_BTM', 'VVM_TOEKOMST_ANDERS_FIETS', 'VVM_TOEKOMST_ANDERS_BROM', 'VVM_TOEKOMST_ANDERS_LOPEN', 'VVM_TOEKOMST_ANDERS_VLIEGTUIG', 'COR_OV_VOORHEEN_TREIN', 'COR_OV_VOORHEEN_BTM', 'COR_BTM_SUBST_1', 'COR_BTM_SUBST_2', 'COR_BTM_SUBST_5', 'COR_TREIN_SUBST_1', 'COR_TREIN_SUBST_2', 'COR_TREIN_SUBST_4', 'COR_OV_SUBST_FIETS_ERV_S1', 'COR_OV_SUBST_FIETS_ERV_S2', 'COR_OV_SUBST_FIETS_ERV_S3', 'COR_OV_SUBST_BROM_ERV_S1', 'COR_OV_SUBST_BROM_ERV_S2', 'COR_OV_SUBST_BROM_ERV_S3', 'COR_OV_SUBST_LOOP_ERV_S1', 'COR_OV_SUBST_LOOP_ERV_S2', 'COR_OV_SUBST_LOOP_ERV_S3']\n",
    "pbz_80nan = pbz_data.columns[pbz_data.isna().mean() > 0.8].tolist()\n",
    "pbz_drop = pbz_dropcols + pbz_80nan\n",
    "pbz = pbz_data.drop(columns=pbz_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All used dfs\n",
    "all = [aut, dab, hhd, pda]\n",
    "\n",
    "# Movement related dfs\n",
    "movement = [dag, pda, pbz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check types of 'all' elements\n",
    "for i, df in enumerate(all):\n",
    "    if not isinstance(df, (pd.DataFrame, pd.Series)):\n",
    "        print(f\"Element {i} is of type {type(df)}, not a Pandas DataFrame or Series.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 'all' elements\n",
    "merged = pd.concat(all, join='inner', axis=1).fillna(0)\n",
    "# Drop duplicates\n",
    "merged = merged.loc[:, ~merged.columns.duplicated()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "move = dag.merge(pda, on = 'PERSID', how='inner').fillna(0)\n",
    "# Drop duplicates\n",
    "move = move.loc[:, ~move.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort move by HHID_x\n",
    "move.sort_values(by='HHID_x', inplace=True)\n",
    "\n",
    "# Store DataFrames split by 'HHID_x'\n",
    "split_dfs = {}\n",
    "prev_HHID = None\n",
    "start_idx = 0\n",
    "\n",
    "for idx, row in move.iterrows():\n",
    "    current_HHID = row['HHID_x']\n",
    "    \n",
    "    if current_HHID != prev_HHID and prev_HHID is not None:\n",
    "        split_dfs[prev_HHID] = move.iloc[start_idx:idx]\n",
    "        start_idx = idx\n",
    "    \n",
    "    prev_HHID = current_HHID\n",
    "\n",
    "split_dfs[prev_HHID] = move.iloc[start_idx:]\n",
    "\n",
    "# Access a specific DataFrame from the dictionary\n",
    "specific_HHID_df = split_dfs[30000715.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make pickles\n",
    "merged.to_pickle('merged_20.pkl')\n",
    "move.to_pickle('move_20.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
